{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a649e8d-68a8-4f79-9746-2d83b5932b1e",
   "metadata": {},
   "source": [
    "### Load and Prepare the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a51e402-1fa7-4b60-ac1e-60384ec5cfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "415ff39b-b046-4ca1-aab0-93c9c4ca47b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data - Replace this with your actual dataset\n",
    "data = {\n",
    "    \"Email Text\": [\n",
    "        \"Hello, I want to know more about the features of Product A.\",\n",
    "        \"I need pricing information for Product B.\",\n",
    "        \"Can you provide specifications for Product C?\",\n",
    "        \"Does Product A come with a warranty? Please let me know.\",\n",
    "        \"I'm considering buying Product B in bulk. Do you offer discounts?\",\n",
    "        \"What are the delivery options for Product C?\",\n",
    "        \"Can you compare Product A and B for me? I'm trying to decide which one to buy.\",\n",
    "        \"I want to integrate Product C into our system. Does it support API access?\"\n",
    "    ],\n",
    "    \"Category\": [\n",
    "        \"Product A\",\n",
    "        \"Product B\",\n",
    "        \"Product C\",\n",
    "        \"Product A\",\n",
    "        \"Product B\",\n",
    "        \"Product C\",\n",
    "        \"Product A / Product B\",\n",
    "        \"Product C\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8236ad3f-4aec-4d33-9cbc-ea6c6ece370f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello, I want to know more about the features ...</td>\n",
       "      <td>Product A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I need pricing information for Product B.</td>\n",
       "      <td>Product B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you provide specifications for Product C?</td>\n",
       "      <td>Product C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Does Product A come with a warranty? Please le...</td>\n",
       "      <td>Product A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm considering buying Product B in bulk. Do y...</td>\n",
       "      <td>Product B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Email Text   Category\n",
       "0  Hello, I want to know more about the features ...  Product A\n",
       "1          I need pricing information for Product B.  Product B\n",
       "2      Can you provide specifications for Product C?  Product C\n",
       "3  Does Product A come with a warranty? Please le...  Product A\n",
       "4  I'm considering buying Product B in bulk. Do y...  Product B"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset into a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f9ab28-6f1f-45f3-8055-7819384d7f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e1e6724-312e-4c6b-b308-7db30357d876",
   "metadata": {},
   "source": [
    "### Text Tokenization & Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c9bc09e-4da6-4220-b54a-b95656d673b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db67a564-85fa-497d-aaaf-4980846c74ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to tokenize the email text\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['Email Text'], padding='max_length', truncation=True)\n",
    "\n",
    "# Tokenize the text (convert to tokens)\n",
    "df['tokens'] = df['Email Text'].apply(lambda x: tokenizer.encode(x, truncation=True, padding='max_length', max_length=64))\n",
    "\n",
    "# Encode the categories/labels into numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "df['Label'] = label_encoder.fit_transform(df['Category'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90363380-5637-4306-a4b4-285507a2578c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4e27a64-94c3-4d99-b5d9-67513afb5915",
   "metadata": {},
   "source": [
    "### Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5126b31-00ae-4489-9f7e-de447d7f3d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertForSequenceClassification  # No need to import AdamW from transformers anymore\n",
    "from torch.optim import AdamW  # AdamW is now part of torch.optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.nn import CrossEntropyLoss  # Add this import\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e759a90-7c96-4c79-b22a-b2721f4c53a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2.1: Split the dataset into training and validation sets\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['Email Text'].tolist(),\n",
    "    df['Label'].tolist(),\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Step 2.2: Tokenize the texts (use the tokenizer you have initialized)\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=64)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8731e373-ebbb-4e31-a381-9595f8101779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2.3: Define a custom Dataset class for the tokenized data\n",
    "class EmailDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])  # Corrected: 'labels' instead of 'label'\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d20d378-be71-4df9-9efc-0df166ed27d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Step 2.4: Create DataLoader for training and validation\n",
    "train_dataset = EmailDataset(train_encodings, train_labels)\n",
    "val_dataset = EmailDataset(val_encodings, val_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Initialize the model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6dff50a-35be-45f1-a813-6485bc82f252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2.5: Initialize the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Step 2.6: Set up the loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Step 2.7: Initialize the learning rate scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, verbose=True)\n",
    "\n",
    "# Step 2.7: Move model to GPU (if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e9433f-7b91-4562-b1c7-de784fa85258",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c40d618-5e65-4bc0-bb62-bf2020068df5",
   "metadata": {},
   "source": [
    "### Model Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8279ff02-6538-440e-93c8-79d087cb3285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Train Loss: 1.3981361389160156, Train Accuracy: 0.3333333333333333\n",
      "Validation Loss: 1.1119264364242554, Validation Accuracy: 0.5\n",
      "Epoch 2/10\n",
      "Train Loss: 1.2753655910491943, Train Accuracy: 0.3333333333333333\n",
      "Validation Loss: 1.0803346633911133, Validation Accuracy: 0.5\n",
      "Epoch 3/10\n",
      "Train Loss: 1.1570532321929932, Train Accuracy: 0.6666666666666666\n",
      "Validation Loss: 1.0844029188156128, Validation Accuracy: 0.5\n",
      "Epoch 4/10\n",
      "Train Loss: 1.0155190229415894, Train Accuracy: 0.8333333333333334\n",
      "Validation Loss: 1.0556362867355347, Validation Accuracy: 0.5\n",
      "Epoch 5/10\n",
      "Train Loss: 0.8900400996208191, Train Accuracy: 0.8333333333333334\n",
      "Validation Loss: 1.0285271406173706, Validation Accuracy: 0.5\n",
      "Epoch 6/10\n",
      "Train Loss: 0.9928539395332336, Train Accuracy: 0.6666666666666666\n",
      "Validation Loss: 1.014777421951294, Validation Accuracy: 0.5\n",
      "Epoch 7/10\n",
      "Train Loss: 0.9684343338012695, Train Accuracy: 0.6666666666666666\n",
      "Validation Loss: 1.0097520351409912, Validation Accuracy: 0.5\n",
      "Epoch 8/10\n",
      "Train Loss: 0.8840656280517578, Train Accuracy: 0.6666666666666666\n",
      "Validation Loss: 1.0086758136749268, Validation Accuracy: 0.5\n",
      "Epoch 9/10\n",
      "Train Loss: 0.892961323261261, Train Accuracy: 0.6666666666666666\n",
      "Validation Loss: 1.0112032890319824, Validation Accuracy: 0.5\n",
      "Epoch 10/10\n",
      "Train Loss: 0.7920951843261719, Train Accuracy: 0.6666666666666666\n",
      "Validation Loss: 1.0318857431411743, Validation Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Define your training and evaluation loop\n",
    "def train_epoch(model, data_loader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "\n",
    "    for batch in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Move batch to the correct device (GPU or CPU)\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track loss and accuracy\n",
    "        total_loss += loss.item()\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        correct_preds += (preds == labels).sum().item()\n",
    "        total_preds += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = correct_preds / total_preds\n",
    "    return accuracy, avg_loss\n",
    "\n",
    "def eval_epoch(model, data_loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            # Move batch to the correct device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # Track loss and accuracy\n",
    "            total_loss += loss.item()\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            correct_preds += (preds == labels).sum().item()\n",
    "            total_preds += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = correct_preds / total_preds\n",
    "    return accuracy, avg_loss\n",
    "\n",
    "# Training loop\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "    \n",
    "    # Training phase\n",
    "    train_accuracy, train_loss = train_epoch(model, train_loader, optimizer, loss_fn, device)\n",
    "    print(f\"Train Loss: {train_loss}, Train Accuracy: {train_accuracy}\")\n",
    "    \n",
    "    # Validation phase\n",
    "    val_accuracy, val_loss = eval_epoch(model, val_loader, loss_fn, device)\n",
    "    print(f\"Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}\")\n",
    "    \n",
    "    # Step the scheduler after the validation loss\n",
    "    scheduler.step(val_loss)  # This adjusts the learning rate based on the validation loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af53372-1393-4b21-9ae3-93d591f7eab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96008f80-039f-48e5-87fe-b356cffec3a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "370b2eff-fd41-4e58-8743-92f693d82bee",
   "metadata": {},
   "source": [
    "# Script to predict the category "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d29dbf83-0217-47ec-8606-9bc252e12bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the email text:  Can you provide specifications for Product A?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted category: Product C\n"
     ]
    }
   ],
   "source": [
    "# Function for making predictions on new email text\n",
    "def predict(model, text, tokenizer, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    # Tokenize the input email text and convert it to tensors\n",
    "    encodings = tokenizer(text, truncation=True, padding=True, max_length=64, return_tensors='pt')\n",
    "    input_ids = encodings['input_ids'].to(device)\n",
    "    attention_mask = encodings['attention_mask'].to(device)\n",
    "    \n",
    "    # Make predictions without tracking gradients\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "    return preds.item()\n",
    "\n",
    "# Example usage to accept user input\n",
    "new_email = input(\"Enter the email text: \")  # Accepting user input for the email text\n",
    "\n",
    "# Assuming 'model', 'tokenizer', and 'device' are already initialized as shown in previous code\n",
    "category = predict(model, new_email, tokenizer, device)\n",
    "\n",
    "# Inverse transform to get the original category label\n",
    "predicted_category = label_encoder.inverse_transform([category])\n",
    "print(f\"Predicted category: {predicted_category[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b8e580-a42a-4723-893f-77815945c527",
   "metadata": {},
   "source": [
    "### Saving the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a193c6ac-76dd-4adb-b394-5d2b1e640904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save_pretrained('fine_tuned_bert')\n",
    "tokenizer.save_pretrained('fine_tuned_bert')\n",
    "\n",
    "# Load the model later for inference\n",
    "model = BertForSequenceClassification.from_pretrained('fine_tuned_bert')\n",
    "tokenizer = BertTokenizer.from_pretrained('fine_tuned_bert')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59019660-67c1-4bb3-ab45-903745c0fe84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
